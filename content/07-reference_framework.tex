\section{Reference framework}

\subsection{Glossary}

\begin{itemize}
	\item \textbf{Methodological transparency (new term)}: a practice in research where the methods, procedures, and analysis techniques are documented and shared in sufficient detail to allow other researchers to understand exactly how the study was conducted.

	\item \textbf{API (Application Programming Interface)}: \enquote{a set of functions and procedures that allow the creation of applications which access the features or data of an operating system, application, or other service, enabling third parties to use the functionality of that software application}. \parencite{sciencedirect_api}

	\item \textbf{LLM (Large Language Model)}: \enquote{a narrow artificial intelligence (AI) system that has been trained on a massive amount of text data to interpret natural language and generate human-like responses to text-based prompts or questions}. \parencite{almarie2023llm}

	\item \textbf{Computational reproducibility}: \enquote{obtaining consistent results using the same input data, computational methods, and conditions of analysis}. \parencite{nasem2019reproducibility}

	\item \textbf{Replicability}: \enquote{an attempt by a second researcher to replicate a previous study is an effort to determine whether applying the same methods to the same scientific question produces similar results}. \parencite{nasem2019reproducibility}

	\item \textbf{Social network site}: \enquote{a networked communication platform in which participants (a) have uniquely identifiable profiles that consist of user-supplied content, content provided by other users, and/or system-level data; (b) can publicly articulate connections that can be viewed and traversed by others; and (c) can consume, produce, and/or interact with streams of user-generated content provided by their connections on the site}. \parencite{aichner2021socialmedia}

	\item \textbf{Social listening}: \enquote{monitoring and analyzing conversations that take place on social and digital channels to gain insights into customer opinions, preferences, and trends. It involves tracking mentions of a brand, product, or relevant keywords, and analyzing the sentiment and context of these conversations}. \parencite{emplifi_sociallistening}

	\item \textbf{Sentiment analysis}: \enquote{can be stated as the procedure to identify, recognize, and/or categorize the users' emotions or opinions for any service like movies, product issues, events, or any attribute as positive, negative, or neutral}. \parencite{bordoloi2023sentiment}

\end{itemize}

\section{State of art}

\subsubsection{Commercial social listening tools}

Commercial social listening tools represent the closest existing solutions to the proposed system in terms of core functionality, offering capabilities such as multi-platform monitoring, sentiment analysis, and trend detection. Prominent platforms like Hootsuite (with Talkwalker) and Meltwater are optimized for business intelligence, brand monitoring, marketing analytics, and customer experience management across multiple social media platforms simultaneously, including Facebook, X (formerly Twitter), Instagram, TikTok, LinkedIn, YouTube, and Reddit, processing millions to hundreds of millions of data sources daily.

However, despite functional similarities, these commercial solutions operate under a fundamentally different scope and design philosophy. These tools prioritize real-time monitoring, competitive intelligence, and actionable business insights over methodological transparency and scientific reproducibility. Their proprietary algorithms, closed-source architectures, and lack of access to raw data or processing methods make it impossible for researchers to verify results, replicate analyses, or understand the underlying computational processes, requirements that are essential for rigorous academic research.

Furthermore, enterprise pricing models (often ranging from thousands to tens of thousands of dollars annually) create significant accessibility barriers for individual researchers, small research teams, and academic institutions with limited budgets. While these platforms offer sophisticated AI-powered analytics and visualization capabilities suitable for corporate decision-making, they are inherently unsuitable for transparent, reproducible scientific research where methodological clarity, open access to data processing methods, and cost-effective accessibility are fundamental requirements. This gap between commercial enterprise tools and academic research needs establishes the motivation for developing a research-focused \enquote{social listening platform} that maintains methodological transparency while providing the analytical capabilities required for scientific study.

\subsubsection{Existing open-source and academic tools}

The landscape of open-source YouTube analysis tools presents a fundamentally fragmented ecosystem where individual components exist in isolation, but no comprehensive, integrated solution addresses the complete workflow required for reproducible academic research focused on YouTube data analysis. This fragmentation represents a critical gap in the available infrastructure for transparent YouTube-based social media research.

While numerous open-source tools provide specific functionalities for YouTube data analysis, such as comment extraction libraries (e.g., YouTube Data API wrappers in Python like \texttt{youtube-search-python}\footnote{\url{https://github.com/alexmercerind/youtube-search-python}}), sentiment analysis packages (e.g., VADER with 4.5K GitHub stars, TextBlob with 9K stars, spaCy with 30K stars), and data visualization frameworks (e.g., Matplotlib, Plotly, D3.js), none combine data collection, processing, analysis, and visualization into a unified, documented, and methodologically transparent platform designed specifically for academic research purposes. Examples of fragmented tools include standalone projects like \texttt{youtube-comments-sentiment-analyzer}\footnote{\url{https://github.com/coskundeniz/youtube-comments-sentiment-analyzer}} and \texttt{YouTube Data Tools}\footnote{\url{https://ytdt.digitalmethods.net/index.php}}, each addressing isolated components but requiring manual integration, custom scripting, and technical expertise to create a complete research pipeline.

This modular approach requires researchers to manually integrate disparate tools, each with different installation requirements, documentation standards, data formats, and API authentication methods, creating substantial technical barriers and introducing potential points of failure in reproducibility. Furthermore, existing tools typically lack the methodological documentation frameworks essential for academic research: documented workflows and processing pipelines that enable independent verification of research findings.

The value proposition of an integrated YouTube social listening tool for academic research thus extends beyond merely providing free alternatives to commercial tools. It centers on establishing documented, validated, and reproducible methodologies within a unified platform that:

\begin{enumerate}
	\item Abstracts API complexity and quota management, including the translation of informal, natural language requests into valid API queries.

	\item Provides standardized data collection and processing workflows.

	\item Offers built-in sentiment analysis and visualization capabilities.
\end{enumerate}

Most importantly, such a tool must explicitly acknowledge and document its dependency on the YouTube API as a fundamental limitation and design consideration, implementing strategies to mitigate API variability through consistent query parameters, timestamp documentation, and transparent reporting of data collection conditions.

This gap between fragmented, component-level tools and comprehensive, methodologically transparent research platforms, combined with the inherent fragility of API-dependent data collection, establishes the primary motivation for developing an integrated free \enquote{YouTube social listening system} designed specifically to meet academic research standards for transparency, reproducibility, and methodological rigor, while explicitly addressing the constraints and limitations imposed by platform API dependencies.

\subsubsection{Key academic studies}

The academic community has increasingly utilized YouTube as a significant data source for social science research. This research is diverse: some studies focus on video content (such as education, health information, or politics); others investigate the recommendation algorithm (examining its relation to news, misinformation, or radicalization); and a significant portion specifically analyzes user comments to understand topics like hate speech, political ideology, gender differences, or sentiment \parencite{deubel2024overview}.

\subsection{Theoretical framework}

\subsubsection{Interactions in the YouTube social network}

Understanding the structure of interactions within YouTube as a social network is fundamental to designing a social listening tool that captures meaningful data for research purposes.

\paragraph{Roles within the YouTube ecosystem}

\textcite{sui2022youtube} identify three primary roles that individuals occupy within the YouTube social network, each representing progressively higher levels of platform engagement.

\begin{itemize}
	\item \textbf{Viewer}: represents represents the most basic level of engagement, consisting of individuals who interact with YouTube solely through passive video consumption. This role requires no account and represents the broadest, least specific form of platform engagement.

	\item \textbf{User}: extends beyond passive viewing to include active engagement mechanisms available through a Google account, such as leaving likes or dislikes on videos, posting comments, replying to existing comments, liking or disliking comments, and subscribing to channels.

	\item \textbf{Creator(or YouTuber)} : occupies the highest degree of platform engagement, actively producing content by posting videos, writing descriptions, curating channels, and building subscriber communities that can elevate them to micro-celebrity status.
\end{itemize}

These roles are not mutually exclusive (creators are simultaneously users and viewers) but they represent distinct analytical categories for understanding platform interactions.

\paragraph{Interaction mechanisms}

Building upon the framework proposed by \textcite{giglietto2012open}, \textcite{sui2022youtube} categorize YouTube interactions into distinct types based on the nature of engagement.

\begin{itemize}
	\item \textbf{Audience interactions}: the views.

	\item \textbf{Social interactions}: the likes, dislikes and comments.

	\item \textbf{Platform interactions}: the metadata like title, date, ID, etc.
\end{itemize}

\paragraph{Extended data categories}

\begin{itemize}
	\item \textbf{Engagement metrics}: quantifiable representations of viewer and user interactions with creators and the platform, including views, likes/dislikes, comments, comment replies, comment likes/dislikes, and subscriber counts. These metrics provide measurable indicators of content popularity, audience sentiment, and community activity.

	\item \textbf{Video/channel characteristics}: structural data independent of user interactions, including total video uploads, video duration, channel start date, video posting frequency, and upload schedules. These characteristics enable analysis of creator behavior patterns and content production strategies.

	\item \textbf{Textual data}: language and discourse elements available for qualitative and quantitative analysis, including video transcripts (extractable through YouTube's built-in transcript function), video titles, video descriptions, channel \enquote{About} pages, video tags, comments, and comment replies. This textual data provides rich material for content analysis, discourse analysis, sentiment analysis, and thematic exploration of community perspectives.

	\item \textbf{Visual data}: image and video content elements including the videos themselves (analyzable as complete recordings or extracted screenshots), video thumbnails, visual banners and annotations, environmental settings, camera angles, and visual representations of creators themselves (enabling analysis of demographic characteristics such as ethnicity, age, and gender presentation). Visual data facilitates ethnographic research, visual rhetoric analysis, and examination of multimodal communication strategies.
\end{itemize}

\subsubsection{YouTube Data API limitations and computational reproducibility challenges}

Beyond the diversity of methodological approaches employed by researchers, the YouTube Data API itself presents inherent technical limitations that must be carefully considered to ensure research reproducibility. Crucially, all YouTube data collection tools, whether open-source or commercial, depend entirely on the YouTube Data API, which is controlled by Google and subject to unilateral modifications without academic input. The discontinuation of the \mintinline{text}{relatedToVideoId} parameter in August 2023, which was previously essential for expanding datasets through recommendation networks, exemplifies how platform decisions can retroactively invalidate established research methodologies and prevent replication of earlier studies.

Recent empirical investigations reveal that the API's Search endpoint exhibits significant temporal variability in returned results. \textcite{efstratiou2025youtube} conducted a systematic audit by running identical queries at 5-day intervals over 12 weeks across six diverse topics, finding that Jaccard similarity (measure of the similarity of two datasets) between video sets declined substantially over time, demonstrating that datasets collected using the exact same historical query may differ vastly based solely on when queries are executed.

These limitations underscore the critical importance of rigorous methodological practices in YouTube-based research. While the API's temporal inconsistency and platform dependency cannot be fully eliminated, researchers can mitigate its impact through transparent documentation of collection timestamps and API parameters and explicit acknowledgment of these platform-imposed constraints in their methodology sections. Tools and frameworks that systematically document API dependencies, timestamp data collection, and maintain transparent records of all methodological decisions are essential for conducting replicable YouTube research within these known limitations.

\subsubsection{Scrum}

Scrum is an agile project management framework that facilitates team collaboration through iterative and incremental development \parencite{schwaber2020scrum}. The framework prescribes for teams to break work into goals completed within time-boxed iterations called sprints, typically lasting two to four weeks \parencite{schwaber2020scrum}. Scrum is based on three pillars (transparency, inspection, and adaptation) and emphasizes self-organization, continuous feedback, and flexibility in response to changing requirements \parencite{schwaber2020scrum}. Originally developed for software development, Scrum has since been successfully applied to various complex projects requiring iterative progress and stakeholder collaboration \parencite{schwaber2020scrum}.
